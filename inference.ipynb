{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import itertools\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from logger import Logger\n",
    "\n",
    "from seqeval.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score as f1\n",
    "\n",
    "from warnings import simplefilter\n",
    "\n",
    "from dataset_simpler import CustomSimplerDataset, NERSimplerDocuments\n",
    "import baseline_lstm_model\n",
    "import lstm_mha_attn_model\n",
    "import bilstm_model\n",
    "import bilstmcrf_model\n",
    "\n",
    "with open('config.yaml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "config_settings = config['model_settings']\n",
    "\n",
    "VALID_BATCH_SIZE = config_settings['batch_size']\n",
    "test_sample_frac = config_settings['test_sample_frac']\n",
    "\n",
    "learning_rate = config_settings['lr']\n",
    "decay = config_settings['decay']\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0,\n",
    "                'drop_last': True,\n",
    "                'pin_memory': True\n",
    "                }\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NERSimplerDocuments()\n",
    "vocab = dataset.get_vocab()\n",
    "labels_to_id = dataset.get_labels_to_id()\n",
    "ids_to_labels = dict(map(reversed, labels_to_id.items()))\n",
    "\n",
    "test_data = dataset.load_test_data()\n",
    "\n",
    "testing_set = CustomSimplerDataset(test_data, labels_to_id, vocab, test_sample_frac)\n",
    "testing_loader = DataLoader(testing_set, **test_params)\n",
    "\n",
    "tokens_to_id = {ch:i for i,ch in enumerate(vocab)}\n",
    "id_to_tokens = dict(map(reversed, tokens_to_id.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testing_loader, ids_to_labels):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        accuracies = []\n",
    "        sentences = []\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        f1_scores = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        print(f'Testing {int(len(testing_loader.dataset)/VALID_BATCH_SIZE)} batches')\n",
    "\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "\n",
    "            inputs = batch[\"tokens\"]\n",
    "            targets = batch[\"labels\"]\n",
    "            attention_mask = batch[\"attention_mask\"]\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "    \n",
    "            logits = model(inputs, attention_mask, targets)\n",
    "\n",
    "            softmax = torch.nn.Softmax(dim=0)\n",
    "            predictions = softmax(logits)\n",
    "\n",
    "            test_predictions = torch.argmax(predictions, dim = 1)\n",
    "\n",
    "            f1_score = f1(targets.flatten().cpu().detach().numpy(), test_predictions.flatten().cpu().detach().numpy(), average='weighted')\n",
    "\n",
    "            sentences.append(inputs)\n",
    "            y_true.append(targets)\n",
    "            y_pred.append(test_predictions)\n",
    "            f1_scores.append(f1_score)\n",
    "\n",
    "            accuracy = torch.sum(torch.eq(test_predictions, targets)).item()/test_predictions.nelement()\n",
    "\n",
    "            accuracies.append(accuracy)\n",
    "    \n",
    "    # if logger != '':\n",
    "    #     logger.log({'test_accuracy': np.sum(accuracies) / len(accuracies),\n",
    "    #                 'test_f1_score': np.sum(f1_scores) / len(f1_scores)})\n",
    "\n",
    "    print(f'Avg f1 score: {np.sum(f1_scores) / len(f1_scores)}')\n",
    "\n",
    "    y_true_labels = []\n",
    "    y_pred_labels = []\n",
    "\n",
    "    for labels in y_true:\n",
    "        y_true_labels.append([[ids_to_labels.get(np.int64(label.cpu().item())) for label in tens_labels] for tens_labels in labels])\n",
    "\n",
    "    for labels in y_pred:\n",
    "        y_pred_labels.append([[ids_to_labels.get(np.int64(label.cpu().item())) for label in tens_labels] for tens_labels in labels])\n",
    "\n",
    "    matrix = confusion_matrix(list(itertools.chain.from_iterable(y_true_labels[0])), \n",
    "                              list(itertools.chain.from_iterable(y_pred_labels[0])), \n",
    "                              labels=list(ids_to_labels.values()))\n",
    "\n",
    "    cm = ConfusionMatrixDisplay(matrix/np.sum(matrix), display_labels=list(ids_to_labels.values()))\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    cm.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    report = classification_report(y_true_labels[0], y_pred_labels[0], output_dict = True, zero_division = 0)\n",
    "    print(f'classification_report:\\n{classification_report(y_true_labels[0], y_pred_labels[0], output_dict = False, zero_division = 0)}')\n",
    "\n",
    "    plt.figure(figsize = (30, 15))\n",
    "    ax = sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, cmap = 'coolwarm', annot=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # if logger != '':\n",
    "    #     logger.log({'classification_report': wandb.Image(ax.figure),\n",
    "    #                 'confusion_matrix': wandb.Image(fig.figure)})\n",
    "    \n",
    "    return sentences, y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 129 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg f1 score: 0.273988587399842\n",
      "Confusion Matrix:\n",
      "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x0000021582FEF3D0>\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.00      0.29      0.01         7\n",
      "        CLS]       0.00      0.00      0.00         0\n",
      "        DATE       0.00      0.00      0.00        14\n",
      "         FAC       0.00      0.00      0.00         1\n",
      "         GPE       0.00      0.00      0.00        13\n",
      "    LANGUAGE       0.00      0.00      0.00         0\n",
      "         LAW       0.00      0.00      0.00         1\n",
      "         LOC       0.00      0.00      0.00         1\n",
      "       MONEY       0.00      0.00      0.00         5\n",
      "        NORP       0.00      0.00      0.00         4\n",
      "     ORDINAL       0.00      0.00      0.00         0\n",
      "         ORG       0.00      0.00      0.00        14\n",
      "        PAD]       0.00      0.00      0.00         0\n",
      "     PERCENT       0.00      0.00      0.00         0\n",
      "      PERSON       0.00      0.00      0.00        17\n",
      "     PRODUCT       0.00      0.00      0.00         2\n",
      "    QUANTITY       0.00      0.00      0.00         3\n",
      "        SEP]       0.00      0.00      0.00         0\n",
      "        TIME       0.00      0.00      0.00         1\n",
      " WORK_OF_ART       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.00      0.02      0.00        86\n",
      "   macro avg       0.00      0.01      0.00        86\n",
      "weighted avg       0.00      0.02      0.00        86\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [PAD] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [SEP] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [CLS] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "with open(f'./trained_models/baseline_lstm.pkl', 'rb') as file:\n",
    "    baseline_lstm_model = pickle.load(file)\n",
    "\n",
    "baseline_lstm_model.eval()\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=labels_to_id['[PAD]'])\n",
    "optimiser = torch.optim.SGD(baseline_lstm_model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = decay)\n",
    "\n",
    "baseline_lstm_sentences, baseline_lstm_y_true, baseline_lstm_y_pred = test(baseline_lstm_model, testing_loader, ids_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:[34093   631    31 29771    31  3081  3082  4943   478  3962   158    21\n",
      "     8 34094 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095\n",
      " 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095\n",
      " 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095\n",
      " 34095 34095] \n",
      "Labels[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
      "Predictions[ 8  8  8  8  8  8  8  8  8  8  7 39  9 39 39 39  9 39 39 39 10 10  9 10\n",
      " 10 10  9 10 10 10  9  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8\n",
      "  8  8]\n"
     ]
    }
   ],
   "source": [
    "print(f'Original Sentence:{baseline_lstm_sentences[0][0].cpu().detach().numpy()} \\nLabels{baseline_lstm_y_true[0][0].cpu().detach().numpy()} \\nPredictions{baseline_lstm_y_pred[0][0].cpu().detach().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 129 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg f1 score: 0.9263999438023569\n",
      "Confusion Matrix:\n",
      "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x000002158D585F90>\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.00      0.00      0.00         8\n",
      "        DATE       0.00      0.00      0.00        14\n",
      "         FAC       0.00      0.00      0.00         1\n",
      "         GPE       0.00      0.00      0.00        24\n",
      "         LOC       0.00      0.00      0.00         4\n",
      "       MONEY       0.00      0.00      0.00         2\n",
      "        NORP       0.00      0.00      0.00        12\n",
      "         ORG       0.00      0.00      0.00        13\n",
      "     PERCENT       0.00      0.00      0.00         5\n",
      "      PERSON       0.00      0.00      0.00        11\n",
      "    QUANTITY       0.00      0.00      0.00         6\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       100\n",
      "   macro avg       0.00      0.00      0.00       100\n",
      "weighted avg       0.00      0.00      0.00       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f'./trained_models/LSTM_MHA.pkl', 'rb') as file:\n",
    "    lstm_attn_model = pickle.load(file)\n",
    "\n",
    "lstm_attn_model.eval()\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=labels_to_id['[PAD]'])\n",
    "optimiser = torch.optim.SGD(lstm_attn_model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = decay)\n",
    "\n",
    "lstm_attn_sentences, lstm_attn_y_true, lstm_attn_y_pred = test(lstm_attn_model, testing_loader, ids_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:[34093   784 23055   143   250   451   515   216     8 34094 34095 34095\n",
      " 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095\n",
      " 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095\n",
      " 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095 34095\n",
      " 34095 34095] \n",
      "Labels[0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
      "Predictions[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(f'Original Sentence:{lstm_attn_sentences[0][0].cpu().detach().numpy()} \\nLabels{lstm_attn_y_true[0][0].cpu().detach().numpy()} \\nPredictions{lstm_attn_y_pred[0][0].cpu().detach().numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-directional LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 129 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\dataset_simpler.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  label_ids = [self.labels_to_id[label] for label in labels_as_lst[index]]\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:911: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg f1 score: 0.5754528211991176\n",
      "Confusion Matrix:\n",
      "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x0000021596187A10>\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CARDINAL       0.00      0.00      0.00         8\n",
      "        CLS]       0.00      0.00      0.00         0\n",
      "        DATE       0.00      0.00      0.00        11\n",
      "       EVENT       0.00      0.00      0.00         0\n",
      "         FAC       0.00      0.00      0.00         6\n",
      "         GPE       0.00      0.00      0.00        18\n",
      "    LANGUAGE       0.00      0.00      0.00         0\n",
      "         LAW       0.00      0.00      0.00         1\n",
      "         LOC       0.00      0.00      0.00         0\n",
      "       MONEY       0.00      0.00      0.00         1\n",
      "        NORP       0.00      0.00      0.00         7\n",
      "     ORDINAL       0.00      0.00      0.00         1\n",
      "         ORG       0.00      0.00      0.00        17\n",
      "        PAD]       0.00      0.00      0.00         0\n",
      "     PERCENT       0.00      0.00      0.00         0\n",
      "      PERSON       0.00      0.00      0.00        14\n",
      "     PRODUCT       0.00      0.00      0.00         1\n",
      "    QUANTITY       0.00      0.00      0.00         0\n",
      "        SEP]       0.00      0.00      0.00         0\n",
      "        TIME       0.00      0.00      0.00         5\n",
      " WORK_OF_ART       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.00      0.00      0.00        91\n",
      "   macro avg       0.00      0.00      0.00        91\n",
      "weighted avg       0.00      0.00      0.00        91\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [PAD] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [SEP] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "c:\\Users\\riyaa\\Documents\\Uni Stuff\\Masters\\Semester 2\\Subjects\\INM706\\INM706-Coursework\\INM706_CW_env\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [CLS] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "with open(f'./trained_models/bilstm.pkl', 'rb') as file:\n",
    "    bilstm_model = pickle.load(file)\n",
    "\n",
    "bilstm_model.eval()\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=labels_to_id['[PAD]'])\n",
    "optimiser = torch.optim.SGD(bilstm_model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = decay)\n",
    "\n",
    "bilstm_sentences, bilstm_y_true, bilstm_y_pred = test(bilstm_model, testing_loader, ids_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:[34093  1398  4377  4378  1935  6332  6333    79  3137    31  7527     8\n",
      "    82   849   172    88  7054    31    95  1493   180   279    26  6466\n",
      "   180   505   231    26  5231  1398    31   180   338   451    10    97\n",
      "   439     8   106 34094 34095 34095 34095 34095 34095 34095 34095 34095\n",
      " 34095 34095] \n",
      "Labels[ 0 11 12 12  0  4  5  0  6  0  7  8  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0 11 12 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0] \n",
      "Predictions[15 15 15 15 15 15 15 15 15 15 26 29 26 26 26 29 26 26 26 26 29 28 29 29\n",
      " 29 28 29 29 29 29 28 23 28 28 28 28 28 28 28 28 23 14 14 14 14 14 14 14\n",
      " 14 14]\n"
     ]
    }
   ],
   "source": [
    "print(f'Original Sentence:{bilstm_sentences[0][0].cpu().detach().numpy()} \\nLabels{bilstm_y_true[0][0].cpu().detach().numpy()} \\nPredictions{bilstm_y_pred[0][0].cpu().detach().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basketball_classification_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
